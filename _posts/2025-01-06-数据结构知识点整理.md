# <i class="fa fa-file-text"></i> 数据结构知识点整理
**整理人：ld**
**日期： 2024年12月9日起（for 2024 fall）**
```
2025.1.5反馈：已完成，如有错误请各位提出
感谢各位对于本人数据结构整理内容的支持和认可，祝各位考试顺利
之后将考虑将pdf版上传交大传承
```
内容挺多的，制作不易！
![](https://notes.sjtu.edu.cn/uploads/upload_ad08e3c77507b7a2802c7c6819e52fdd.png)

==反馈、交流板块：==[请点击这里哦:smiley::tada::tada::tada:！！！](
https://docs.qq.com/doc/DVHFaWFNxUkxha3Fp)

----
# 第零部分 前言目录
## 0. 前言（我写的）：
:::spoiler 我的一些个人评价，点击能打开来
- 作为一门只有3学分的课程，个人认为在学完了c++后，数据结构前面的部分对于有编程基础的同学（例如以应试教育方式全部学过Python以及栈、队列等概念的浙江同学）来说，~~还是太过于熟悉~~。就算是对于只是刚刚学过程设的其他工科同学来说，其难度也并不高。所以，本人说实话，在听了几节老师的课后，~~后面就全部没来上了~~:smiley:。不过必须要说一句，后面的部分确实是有难度的。
- 说这么多，只是想强调一下，只要程设有认真学了（尤其是class结构，以及template模板的应用），这门课**在代码上**基本上问题不大，相信各位，也祝各位期末加油鸭:smile::tada:
- 本次整理将会全部按照课本的顺序来，重点在于基础的掌握，代码一并经过解释放在最后，由于时间限制，所以做不到事无巨细，还请各位理解
- 目前主要参照：上课的ppt
- 另外，最近正好发现了这个协作笔记的网站，个人觉得确实不错，所以就在这里整理所有知识点:wink:
:::

---
- 一些注意点：
**加粗部分是标题、概念和我认为重要的一些东西**
==高亮部分是一些注释，以及我对相关知识点的一些**评价**和带有个人主观观点的**题外话**==
```
一些以这样小框形式呈现的内容，是我给自己留的注释，用于帮助完善笔记
```

一些需要分类的东西会使用**思维导图**来展示
一些重要的东西会选取范磊老师ppt上面的图片进行解释（所以可能会有问题）
一些我认为需要理解的代码会放在正文里，至于其他的，可以自己看书


## **目录：**（点击可传送）
==一些更低级别的标题被提到了更高一级，主要是因为个人觉得这些内容偏重点+比较有难度，从而方便一次性链接直达==
==取消了源代码部分，第一是我写了大家也不一定会看，第二是太过于复杂了:cry:==
[TOC maxlevel=2]

## 1.数据结构的引言
- 这一章重点讲解**数据和算法结构**，主要是基础内容
### 1.1数据的逻辑结构
- 逻辑结构与数据元素的内容、个数**无关**
```markmap
# 逻辑结构

## 线性结构
- 数据元素构成有序序列
- 我们会在**第一部分**学到
## 树状结构
- 数据元素形成一个层次关系
（只有一个前驱）
- 我们会在**第二部分**学到
## 集合结构
- 数据元素间的次序任意
- 我们会在**第三部分**学到
## 图状结构
- 最一般，前驱后继数目不限
- 我们会在**第四部分**学到
```

- 数据结构中会有各种**操作**和**运算**
常见的：创建、清除、**插入**、**删除**、**搜索**、更新、访问、**遍历**（每个元素**恰好被访问一次**）

### 1.2存储实现
- 包括两个部分：
1. 数据**元素**的存储
2. 数据元素之间的**关系**的存储 
（实际编程中还会增加一些哑节点，比如链表中的空的头结点）
```markmap
# 存储实现

## 顺序存储
- **连续**存储区域
## 链接存储
- 存储可以**分散**，关系通过**指针**指出
## 哈希存储方式
- 专用于**集合**结构的数据存放方式
各个结点**均匀**地分布在一块连续的存储区域中
用一个哈希函数将数据元素和存储位置**关联**起来
## 索引存储方式
- 所有的存储结点按照生成的次序**连续存放**
另外设置一个**索引区域**表示结点之间的关系
```

### 1.3算法分析
- **数据结构**是讨论一组数据的处理问题，每一种操作的实现都是一个算法
每种操作有多种实现方式，因此也有**好坏之分**，需要进行**评价**
- 数据结构主要考虑的是代码的**时空性能**，即**时间和空间**的消耗
#### 时间复杂度分析
- **渐进表示法**：只考虑运行时间函数的**数量级**
- 我们主要需要掌握**大O表示法**，只需要给出一个**数量级**，表示其受哪一数量级影响**最大（即最大的数量级）**，忽略小的数量级

- 常见的大小比较： O(1) < O(logN) < O(N) < O(NlogN) < O(N^2^) < O(N^k^)(k>2) < O(k^N^)(k>1) < O(N!) < O(N^N^)

- **求和定理**：两个程序若先后运行，运行时间受**数量级高的**影响
- **求积定理**：若相乘，则时间复杂度**相乘**
- 看程序时，基本上就看代码会**重复**运行多少次，在程序中找出**最复杂**、运行时间最长的程序段，计算它的时间复杂度。也就是整个程序的时间复杂度
==也就是取最大的==

#### 空间复杂度分析
- 直接看需要多少存储空间即可，表示方法与时间复杂度（大O）相同
- 根据以上的知识，我们可以通过**改变算法**来尝试降低其两个复杂度

### 1.4 面向对象方法
- 将数据结构的存储和处理过程**封装**起来做成一个个工具，通过实用的工具来解决问题
==也是本课会用到的方法，但是着实有点复杂==

# 第一部分 线性结构
第一部分是**线性表**，包括**栈**和**队列**两种有特点的线性表
==个人认为难度不大，对有基础的同学们算是复习（如果觉得难的话，请忽略上一句:cry:）==

## 2.线性表
### 2.0定义
- **定义**：N个具有相同特征的结点A~0~, A~1~, …, A~N-1~构成的集合。除了A~0~和A~N-1~外，每个元素都有**唯一**的前趋和后继
- 表的术语：N（表的大小）、A~0~（首结点）、A~N-1~（尾结点）、空表、A~i~在表中的位置为i

### 线性表的实现（重点介绍其结构、算法特点）

==这里必须说明，下文的代码会是能运行情况下尽量**简洁**的，去除了一些细节==

### 2.1顺序实现
顺序存储的优点在于其访问十分**快速**（根据索引找到内存地址），但是一旦要对数据进行修改，就要对很多数据进行**移动**，而且有可能浪费空间。
#### 2.1.1构造
![](https://notes.sjtu.edu.cn/uploads/upload_19e937c27da2f28c052d79897c579fe2.png =600x)
```cpp
// 构造函数
template <class elemType>
seqList<elemType>::seqList(int initSize) // 传入自己确定的表的大小
{
    data = new elemType[initSize]; // 申请数据存储空间
    maxSize = initSize;            // 定义最大大小
    currentLength = 0;             // 初始的长度当然是0
}
```
#### 2.1.2插入insert()与删除remove()
- 插入元素需要后面元素后移以留出空间，时间复杂度O(N)
![](https://notes.sjtu.edu.cn/uploads/upload_740a68d859493b676f52c52c8e53c607.png =600x)
```cpp
// 插入函数
template <class elemType>
void seqList<elemType>::insert(int i, const elemType &x)
{
    for (int j = currentLength; j > i; j--)
        data[j] = data[j - 1]; // i后面的全部后移一位，空出位置来插入新元素
    data[i] = x;
    ++currentLength; // 现有大小+1
}
```
==注意a[currentLength]因为a的索引从0开始，所以其实是空值==
- 删除同理，需要后面元素移动**填补空缺**，时间复杂度O(N)
![](https://notes.sjtu.edu.cn/uploads/upload_46b2d5ca1e595adb5c6794dafb199866.png =600x)
```cpp
template <class elemType>
void seqList<elemType>::remove(int i)
{
    if (i < 0 || i > currentLength - 1)
        throw OutOfBound(); // 检查删除的位置是否合法，不必多在意
    for (int j = i; j < currentLength - 1; j++)
        data[j] = data[j + 1]; // i后面的元素全部前移
    --currentLength;           // 现有大小-1
}
```
#### 2.1.3扩容doublespace()
顺序实现需要再表满的时候进行**扩容（链表实现不需要）**，从而存储更多的数据
==之前上个学期程设期末的最后一题其实就可以用这个方法实现，但是那时的我还是太菜了:cry:==
![](https://notes.sjtu.edu.cn/uploads/upload_2d22398d8cd21c463cf4ec0ffeb59710.png)
```cpp
// 扩大空间的函数，简洁不下去了，就有这么多行
template <class elemType>
void seqList<elemType>::doubleSpace()
{
    elemType *tmp = data; // 设立一个tmp指针，来存储原来表的数据
    maxSize *= 2;
    data = new elemType[maxSize]; // data变为了新的、更大的表
    for (int i = 0; i < currentLength; ++i)
        data[i] = tmp[i]; // 将原来的数据copy过去
    delete[] tmp;         // 记得删除，避免内存泄漏
}
```

### 2.2链表实现
==链表的优点就是修改迅速方便，但是查找就需要慢慢地一个一个查==
#### 2.2.1构造
创建一个**头结点**（节点中**没有元素**）即可
- 头结点的用途：避免特殊情况（如空链表等）需要额外代码处理
#### 2.2.2插入insert()与删除remove()
操作本身的复杂度是O(1)，但是需要遍历、搜索需要插入的位置的话，复杂度就是O(N)
![](https://notes.sjtu.edu.cn/uploads/upload_185e07cc6be8dd77a6694190a423e0a9.png)


- 分为2步：
1.移到要插入的地方（位置i）
2.创立新节点，其指针指向a~i+1~，a~i~则**指向该节点**
```cpp
// 插入函数
template <class elemType>
void sLinkList<elemType>::insert(int i, const elemType &x)
{
    node *pos;
    pos = move(i - 1); //第一步
    pos->next = new node(x, pos->next); // 插入一个新的节点
    ++currentLength;
}
```
![](https://notes.sjtu.edu.cn/uploads/upload_1d3a4aabc5b38b6a8ed0d7216fef3dbe.png =500x)
- 分为3步：
1. 移到要删除的地方（位置i-1）
2. 修改指针，a~i-1~的指针指向**a~i+1~**，删掉a~i~
3. 把节点删除掉释放内存
```cpp
// 删除函数
template <class elemType>
void sLinkList<elemType>::remove(int i)
{
    node *pos, *delp;
    pos = move(i - 1);
    delp = pos->next;       // 找到想要删除的节点
    pos->next = delp->next; // 绕过delp
    delete delp;
    --currentLength;
}
```
#### 2.2.3双链表
特点：多了一个prior字段，其指向**前驱结点**，另外多一个尾节点tail，其他的差别不大
不过要清楚插入和删除节点相比单链表的变化
![](https://notes.sjtu.edu.cn/uploads/upload_36430b9c4192977b72e17f9dc0efc84a.png =500x)

#### 2.2.4单循环链表
特点：最后一个节点**指向**第一个结点，一般不设头结点（了解特点即可）
![](https://notes.sjtu.edu.cn/uploads/upload_0cdb0940fd3f283bd7bc24cbcb521dea.png =500x)

#### 2.2.5双循环链表
- 特点：头结点中prior字段给出**尾结点**的地址，尾结点中next字段给出**头结点**的地址 
一般也**不设头尾结点**

（了解特点即可）

![](https://notes.sjtu.edu.cn/uploads/upload_b7481f794dbb5ac69c77c2d08880e1ea.png =500x)


## 3.栈
### 3.0基础
**特点**：**先进后出**结构，最先到达栈的结点将最晚被删除
![](https://notes.sjtu.edu.cn/uploads/upload_fa6ae0b77d7487d3c07e22ff1b4edced.png =500x)
- 相关概念
**栈底(bottom)**：结构的首部（先进栈的节点的位置）
**栈顶(top)**：结构的尾部（后进栈的节点的位置）
**出栈(pop)**：结点从栈顶删除 
**进栈(push)**：结点在栈顶位置插入 
**空栈**：栈中结点个数为零时

### 栈的实现
### 3.1顺序实现
顺序实现中除了**扩容**需要O(N)（平均下来N次进栈才会有一次扩容，其实整体来说复杂度也算是O(1)），其余的均为O(1)
#### 3.1.1构造
用数组的**后端**表示栈顶，这样进栈和出栈不会引起顺序表中大量数据的移动
![](https://notes.sjtu.edu.cn/uploads/upload_2c2a19448a0ef527ab61e73d00fa4c16.png =500x)
==注意：top**设为-1**==
==栈的top指向的永远是**栈顶元素的位置**（所以空栈时top=-1）（与队列区分）==
#### 3.1.2进栈&出栈
- 分成2步：
1.top值+1（进）或-1（出）
2.加入新值或返回出栈值
#### 3.1.3判断空栈
判断top是否为-1即可
#### 3.1.4扩容
顺序存储的扩容操作已经是一个绕不开的话题，这里的话扩容操作与其他的**类似**
### 3.2链接实现
- 3个注意点：
1.**不需要头结点**，只需要单链表（因为栈的操作只与栈顶有关）
2.单链表的头指针指向**栈顶**
3.所有操作时间复杂度**均为O(1)**
![](https://notes.sjtu.edu.cn/uploads/upload_61a2be484dd9da3792a739d0333d506a.png =500x)
#### 3.2.1构造
将top设为**空指针**（NULL）
==就是这么简单==
#### 3.2.2插入
1.创立新元素，其**指向原有的栈顶元素**
2.头指针指向**新元素**
==头指针指向栈顶==
#### 3.2.3删除
1.指针指向**下一个元素**
2.返回出栈元素
#### 3.2.4判断空栈
只要判断top指针是否为**空**即可
### 3.3栈的特点
1.递归函数的**调用结构**类似于栈，如快速排序等等
==所以如果想让使用递归函数的算法不用递归函数，可以自己**人工构造**一个栈来模拟函数的调用过程==
2.符号匹配（如括号）与检查可以使用栈来实现

==关于栈最小空间大小的讨论：（这只是个人的经验，听不懂也没关系）
1.如果是根据出栈的序列判断栈的大小（即从理论上），那么如果一个元素入栈后马上出栈，那么**也会占据一个空间**
2.如果是例如后缀式实现的分析，那么在实际处理中，一个元素岀栈马上入栈，可以不占据空间==

## 3.4表达式的计算（栈的应用）
其用栈来实现，不过内容比较重要
对于一个表达式 a+b
**前缀式**：+ab
**中缀式**：a+b
**后缀式**：ab+ 后缀式可以**不考虑运算符的优先级**（不使用括号）
### 3.4.1如何用栈实现后缀表达式
1.若读到的是操作数，则将其进栈。
2.若读到的是运算符，则将栈顶的两个操作数**出栈**，（（除法时）**后**弹出的操作数为**被操作数**，先弹出的为操作数）使其完成运算符所规定的运算，并将结果进栈。（1个符号对应2个数）
3.最后栈里面剩下的数就是结果。
### 3.4.2如何用栈实现中缀表达式转后缀表达式
（式子里的数字直接输出）
| 符号 | 操作 |
| -- | -- |
|(|直接进栈|
|)|将栈中的运算符依次出栈。出栈操作一直进行到遇到相应的开括号为止。将开括号出栈。|
| + - * / |如果栈顶运算符优先级高，则栈顶运算符出栈；出栈操作一直要进行到**栈顶运算符优先级比它低**为止，然后将新读入的运算符进栈保存。|
|结束| 将栈中所有的剩余运算符依次出栈，并放在操作数序列之后，直至栈空为止。|
一个例子：
![](https://notes.sjtu.edu.cn/uploads/upload_65ef26fea5b8a67f5179889dcfd86195.png =600x)


## 4.队列
### 4.0基础
**特点**：**先进先出**结构，==难道不就跟排队一样？进去肯定先是队尾，然后排队到队头==
队列图示&相关概念：
![](https://notes.sjtu.edu.cn/uploads/upload_c4ad370ba6421cb121c0ba74851e8b50.png =400x)
### 队列的实现
### 4.1顺序实现
使用数组存储队列中的元素
队列中的结点个数最多为MaxSize个 
元素下标的范围从0到MaxSize-1。
- 组织方式：
#### 1.队头位置固定
![](https://notes.sjtu.edu.cn/uploads/upload_fb5a7b3bb6d9769fe73da8b022b08183.png =500x)
缺点：出队会让大量数据移动，O(N)复杂度，==所以还是别这样实现吧==
#### 2.队头位置不固定
![](https://notes.sjtu.edu.cn/uploads/upload_c3b905b456ee52c04754f47d1c3a1ee0.png =500x)
判断队满：rear =  MaxSize - 1（实际上元素个数不一定是Maxsize）
缺点：O(1)复杂度，浪费空间，==我更讨厌这个，不可持续发展！:anger:==
==注意：front指向的是队首，这个地方**没有元素**，rear指向队尾，这里有元素==
#### 3.循环队列（队头位置也不固定）
两个指针到了最后都回到第一个（即下标0，这样可以重复利用空间）
只不过**有效存储单元少一个**（区别空队列（rear=front）和满队列（(rear+1)%maxsize=front)）（注意+1）
```cpp
//入队操作：
rear = (rear + 1) % MaxSize;
elem[rear] = x;
//出队操作：
front = (front + 1) % MaxSize;
//队列为空判断
if(front == rear)
//队列为满判断
if((rear + 1) % MaxSize == front) //即队尾往后移一个就是队首
```
![](https://notes.sjtu.edu.cn/uploads/upload_3bc9edad65ed25b94d0acfcb3f43f83e.png =400x)
#### doublespace()扩容函数
（这里**有变化**了）
```cpp
template <class elemType>
void seqQueue<elemType>::doubleSpace()
{
    elemType *tmp = elem;
    elem = new elemType[2 * maxSize];
    for (int i = 1; i < maxSize; ++i)
        elem[i] = tmp[(front + i) % maxSize];
    //复制原有的信息到扩容的地方，但是根据循环列表的性质，是(front + i) % maxSize
    front = 0;
    rear = maxSize - 1;
    maxSize *= 2;
    delete tmp;
}
```
### 4.2链接实现
==（我觉得队列用链接实现更好一些）==
- 特点：
1.**没有头结点**的设立
![](https://notes.sjtu.edu.cn/uploads/upload_25db7dcf172e797d1b4efd55e0298d70.png =500x)
2.我们把单链表的表头作为队头，单链表的表尾作为队尾。队列要对表的两端作操作，所以我们同时记住**头尾结点**的位置，需要两个指向单链表结点的指针front和rear
3.队列为空or初始化（构造）时，单链表中没有结点存在，即头尾指针**都为空指针**
### 4.3队列的应用
其实就是模拟各种需要“排队”的场景

==第5章应该没学==

```
12.12完成第一部分
```

----

# 第二部分 树状结构
第二部分是树，包括二叉树和堆。
==对我个人而言，树的最最基础的理论知识有些学过，按照高考标准学的，~~所以掌握程度自行体会（doge）~~。但是有些东西（如AVL树）的确是没学过的，这些知识个人觉得算是数据结构里最难的（尤其是AVL树），大家共勉。==

## 6.树
### 6.0基础
树形结构是处理具有**层次关系**的数据元素
(1)有一个被称之为**根**(root)的结点
(2)其余的结点可分为m(m≥0)个互不相交的集合T~1~，T~2~，…，T~m~，这些集合本身也是一棵树，并称它们为根结点的**子树(Subtree)**。每棵子树同样有自己的根结点。
(3)可以有多个直接后继，只能有一个直接前驱
==从图形上~~长得像棵树不就行了~~==
![](https://notes.sjtu.edu.cn/uploads/upload_3fb72633f3a060ad9f3b9cc31f2e1a69.png =400x)
### 6.1相关术语
==必须要提的一句是，“结点”和“节点”两个写法**似乎都是对的**，我后面打字可能两种写法都会爆出来==
```markmap
# 术语
## 结点
### 根结点
- 起始节点，没有父节点
### 叶结点
- 没有**子节点**（度为0）
### 内部节点
- 上两个类型的补集
### 儿子结点
- 结点的**下一层**结点
### 父亲结点
- 结点的**上一层**结点
### 兄弟结点
- 同一**父节点**的结点
### 祖先结点
- 从**根到该节点**的所有结点
### 子孙（后代）结点
- 某个节点的**所有下层**结点
## 其他
### 度
- 直接子结点的数量
- 树的度由**度最大**的结点决定
### 层次
- 直观地看在第几层即可
- 根结点在**第1层**！！！
### 高度
- 看有最大几层即可
### 有序树
- 子树从左到右有顺序，即分左右子树
### 无序树
- 子树无顺序
### 森林
- 若干树的集合，树互不相交
```

## 6.2二叉树
### 6.2.1概念
==我觉得还是简单地去理解：分成两叉的树（注意是个有序树，区别左右）==
![](https://notes.sjtu.edu.cn/uploads/upload_33041d15ca8315b995f5b4760d93d8a0.png =600x)
**满二叉树**：高度为k并具有2^k^-1个结点的二叉树（每一层结点个数都达到了最大值）
**完全二叉树**：==我觉得满二叉树+最下面一层结点依次从左至右更好理解一点==
### 6.2.2性质
```markmap
# 性质
## 1.第i层上最多有2^(i-1)个结点（i≥1）（废话）
## 2.高度为k的二叉树，最多具有2^k-1个结点（2的等比数列求和）
## 3.如果叶子结点数为n0，度数为2的结点数为n2，则有:n0=n2+1成立。
## 4.具有n个结点的完全二叉树的高度 k = log2n（向下取整）+1 
## 5.一个完全二叉树若树的根节点编号1每一层自左至右依次编号，一个节点编号为i
## 接5.父节点编号为i/2（向下取整）
## 接5.左儿子的编号为2i，右儿子编号2i+1（如果有的话，即<n）
```
### 6.2.3遍历
由于树的特殊结构，所以有**不同的遍历方式**
- **前序遍历：根左右**
==形象地说，这种遍历能往左走就往左走，不行的时候往右遍历==
分析时**第一个一定是根节点**。
- **中序遍历：左根右**
分析时，关注**根节点的位置**（会在遍历序列的中间），在其左边的就是左子树，在右边的就是右子树。
- **后序遍历：左右根**
分析时，最后一个一定是根节点。
- 这三种遍历方式采取的是**递归**的思想，即遍历到子树之后，将子树视为一个树继续遍历。
只要知道一棵树的前、中or中、后遍历（**前、后不行**，有时候无法辨别左右子树关系）的具体情况，我们就能推知树的所有结构信息。
- **层次遍历**：一层一层从左至右遍历过来（最废话的一种方式）

### 二叉树实现
### 6.2.4顺序存储
根据**左子树2i，右子树2i+1**的特点即可。
根结点的下标**为1**。
可能会浪费存储空间。
![](https://notes.sjtu.edu.cn/uploads/upload_bf15e050e56064ae394b65edfec8d84b.png =400x)
### 6.2.5链接存储（更为通用）
- 根据存不存父节点，有两种版本
1. 标准形式（只存左右节点）：

| left | data | right |
| ---- | ---- | ----- |

![](https://notes.sjtu.edu.cn/uploads/upload_a36b876bf590052d26538ce22bd25871.png =600x)
2. **广义**标准形式（还存父节点）：
从左至右:

| data | left | parent | right |
| ---- | ---- | ------ | ----- |

![](https://notes.sjtu.edu.cn/uploads/upload_9e38d4e983d878a4488f7cad0dd427c4.png =600x)

#### 构造
设根节点指针root = NULL（初始为空指针）
#### isempty()
判断root是否为NULL
#### 前中后递归遍历
采取递归的形式，根据是前序、中序还是后续来安排遍历顺序。
基本来说前序遍历在需要遍历的操作中选择的次数会多一点，我觉得因为前序遍历更符合我们遍历的直觉。
```cpp
//这个是前序遍历，需要注释
template<class T>
void binaryTree<T>::preOrder(binaryTree<T>::Node *t)  const
{       if (t == NULL) return;
	    cout << t->data << ' ';//先输出根结点
	    preOrder(t->left);//第二个是左结点
	    preOrder(t->right);
}
```

#### 6.2.5前中后非递归遍历（不知道是不是重点）
- 前序遍历：
开始时，把二叉树的根结点存入栈中。然后重复以下过程，直到栈为空：
从栈中取出一个结点，输出根结点的值，然后把**右子树，左子树**放入栈中。
- 中序遍历：
根节点进栈后，先让**左子树进栈**。左子树访问完后自然就到根节点，访问完后右子树进栈。
所以，根结点要进栈两次。当要遍历一棵树时，将根结点进栈。
根结点第一次出栈时，它**不能被访问**，必须重新进栈，**并将左子树也进栈**。根节点第二次出栈是正常的
```cpp
template <class Type>
void BinaryTree<Type>::midOrder() const
{
    linkStack<StNode> s;
    StNode current(root);

    cout << "中序遍历: ";
    s.push(current);
    while (!s.isEmpty())
    {
        current = s.pop();
        if (++current.TimesPop == 2) // 意思就是访问过一次（左子树已经遍历），访问一次就输出
        {
            cout << current.node->data;
            if (current.node->right != NULL)
                s.push(StNode(current.node->right));
        }
        else // 还没访问左子树，那么先访问左子树
        {
            s.push(current); // 重新入栈！
            if (current.node->left != NULL)
                s.push(StNode(current.node->left));
        }
    }
}
```
- 后序遍历：
根节点需要**出栈三次**，其他的倒没什么
（代码略）

#### 6.2.6层次遍历
**层次遍历**得专门讲一讲，这里少见的**不用递归函数**，而是利用了**队列**，在遍历时根结点出队时，会让其**子结点**入队，从而保证了层次遍历的有序性。（不理解的话自己可以模拟一下）
- **创建树**也利用到了层次遍历的相关用法，即遍历到的时候输入其两个子结点的值，然后两个子结点入栈，准备之后的再一轮输入。正文部分就不再重复代码了。
- **输出树**也是同理的，利用层次遍历进行输出，这样的遍历方式更加易于我们观看和了解。
```cpp
template <class T>
void binaryTree<T>::levelOrder() const
{
    linkQueue<Node *> que;
    Node *tmp;
    cout << "\n层次遍历：";
    que.enQueue(root);
    while (!que.isEmpty())
    {
        tmp = que.deQueue();      // 队头出队
        cout << tmp->data << ' '; // 访问队头结点
        if (tmp->left)
            que.enQueue(tmp->left); // 左子树入队
        if (tmp->right)
            que.enQueue(tmp->right); // 右子树入队
    }
}
```

### 6.3哈夫曼树
#### 6.3.0编码用树来表示
- 计算机每个字符用一个**编码**表示，而且是**二进制**的
- 对应在树中的话，**0**相当于**向左**，**1**相当于**向右**
#### 6.3.1特点
- 目的：根据数据的出现频率进行**不同长度的编码**，从而**节省空间**
- **哈夫曼树**是一棵**最小代价**的二叉树，在这棵树上，所有的字符都包含在叶结点上。
要使得整棵树的代价最小，显然权值大的叶子应当尽量**靠近树根**，权值小的叶子可以适当离树根远一些
#### 6.3.2构建方法
从当前集合中选取并去除权值**最小、次最小**的两个结点，以这两个结点作为内部结点 b~i~ 的左右儿子，b~i~ 的权值**为其左右儿子权值之和**（生成了一棵新树）并加入其中。这样，在集合A中，结点个数便**减少了一个**。
这样，在经过了n-1次循环之后，集合A中只剩下了一个结点，这个结点就是**根结点**。

例子：
![](https://notes.sjtu.edu.cn/uploads/upload_831ecc1d71a7d45f9c26180129da68d2.png =500x)
（省略中间过程）
![](https://notes.sjtu.edu.cn/uploads/upload_3b5743aceb03b0547f2dc7b6511f3abd.png =300x)

==哈夫曼编码可以保证通过连续的一串编码得出相关内容==
#### 6.3.3实现
注意点：新生成的结点编号从size-1到1（即n-1个），**原有的**结点位置从size到2×size-1
这里就放一下构造新二叉树的过程
```cpp
for (i = size - 1; i > 0; --i)
{
    min1 = min2 = MAX_INT;//初始化最小值
    x = y = 0;
    for (int j = i + 1; j < length; ++j)
        if (elem[j].parent == 0)//找到最小值和次小值
            if (elem[j].weight < min1)
            {
                min2 = min1;
                min1 = elem[j].weight;
                x = y;
                y = j;
            }
            else if (elem[j].weight < min2)//如果不是最小值，则看看是不是次小值
            {
                min2 = elem[j].weight;
                x = j;
            }
    elem[i].weight = min1 + min2;//更新新的节点权值
    elem[i].left = x;
    elem[i].right = y;
    elem[i].parent = 0;
    elem[x].parent = i;
    elem[y].parent = i;
}
```

## 6.4树和森林
### 6.4.1树的存储实现
1. **标准形式**（广义的树需要加个指向父亲节点的指针）
![](https://notes.sjtu.edu.cn/uploads/upload_4e8fb67f7cddb9f93400562ce19a6600.png =400x)
2. **孩子链表示法**
将每个结点的所有孩子组织成一个链表。
树的节点由两部分组成：存储数据元素值的数据部分、指向孩子链的指针
![](https://notes.sjtu.edu.cn/uploads/upload_e8d04011af64943aca5b8fc093035f49.png =400x)
3. **孩子兄弟链表示法**
![](https://notes.sjtu.edu.cn/uploads/upload_08ba86bb444bbdaf799539fce890750f.png)
4. **双亲表示法**
适合求祖先结点，但不便求子孙结点
![](https://notes.sjtu.edu.cn/uploads/upload_97a14a75d3c4d83c7549eafaec63e5de.png =500x)
### 6.4.2树的遍历
- 前后序遍历：**没有中序遍历**，二叉树的左右结点变为一个一个子结点遍历，==我觉得废话==
- 层次遍历：==废话==
### 6.4.3树、森林和二叉树
- 二叉树是结构最简单、运算最简便的树形结构，但对很多问题来讲，其自然的描述形态是树或森林。树的**孩子兄弟链表示法**（见上面）就是将一棵树表示成二叉树的形态。
![](https://notes.sjtu.edu.cn/uploads/upload_268dfe30f0b4526d0d998e74f6c2a4fe.png =400x)
- 森林
![](https://notes.sjtu.edu.cn/uploads/upload_c741378d5f4493c9b91ba4b5efecc594.png =500x)
![](https://notes.sjtu.edu.cn/uploads/upload_c7ff271095877f73d696ab18fe873a3f.png =400x)



## 7.优先级队列
### 7.0定义
- 结点之间的关系是由**结点的优先级**决定的，而不是由入队的先后次序决定。**优先级高**的先出队，优先级低的后出队。这样的队列就是优先级队列
### 7.1简单实现（利用已学的东西）
- 两种方法：
1. 入队时，按照优先级在队列中**寻找合适的位置**（O(N)），将新入队的元素插入在此位置。出队操作的实现保持不变（O(1)）。
2. 入队操作的实现保持不变，将新入队的元素放在队列尾（O(1)）。但出队时，在整个队列中**查找优先级最高的元素**（O(N)），让它出队。

## 7.2二叉堆
堆是一棵完全二叉树（结构性），而且具有（有序性）（见下）
==相同的数据可以有不同的建堆结果==
1. k~i~≤k~2i~且 k~i~≤k~2i+1~(i=1,2,…,[n/2])
**最小化堆**
![](https://notes.sjtu.edu.cn/uploads/upload_419f6afe15e078914b10da3d37222c13.png =200x)

2. k~i~≥k~2i~且 k~i~≥k~2i+1~(i=1,2,…,[n/2])
**最大化堆**
![](https://notes.sjtu.edu.cn/uploads/upload_d2fe243ead0b34f5fb4f215f0e8f511e.png =200x)
### 二叉堆的实现（以最小化堆为例）
- 可以顺序存储
#### 插入enqueue
- 新结点会先插入到完全二叉树**最后一个结点**，然后**根据情况**来向上移动
- 新结点的向上移动称为向上过滤(percolate up)（时间复杂度O(logN)）
```cpp
template <class Type>
void priorityQueue<Type>::enQueue(const Type &x)
{
    // 向上过滤
    int hole = ++currentSize;
    for (; hole > 1 && x < array[hole / 2]; hole /= 2) // 只要数据够小，就会一直往下
        array[hole] = array[hole / 2];    // hole/2是父节点，hole是子节点，父节点数据向下移动
    array[hole] = x;
}
```
#### 删除dequeue
- 找到空结点（实际上是使用最后一个结点替换了该结点）的一个较小的子结点放入空结点，**移动空结点往下一层**
- 空结点是往下移动（向下过滤，即percolateDown，后面建堆会用到）（时间复杂度O(logN)）
```cpp
//需要追加解释
template <class Type>
Type priorityQueue<Type>::deQueue()
{
    Type minItem;
    minItem = array[1];
    array[1] = array[currentSize--];
    percolateDown(1);//从根节点开始向下调整
    return minItem;
}
template <class Type>
void priorityQueue<Type>::percolateDown(int hole)
{
    int child;
    Type tmp = array[hole];
    for (; hole * 2 <= currentSize; hole = child)
    {
        child = hole * 2;
        //如果有右孩子，且右孩子小于左孩子，则将右孩子赋值给child
        if (child != currentSize && array[child + 1] < array[child])
            child++;
        if (array[child] < tmp)
            array[hole] = array[child];
        else
            break;
    }
    array[hole] = tmp;
}
```
#### 构造（建堆）
- 构造堆的时间复杂度可以为O(N)（只考虑最后的有序性，即在全部插入完后才调整）
- 为什么呢？因为对于一棵高度为h，包含了N=2^h+1^-1个结点的满二叉树，结点的高度和为N–h–1，说明操作数小于N
证明：
$$
s = \sum_{i=0}^h 2^{i}(h-i)=N-h+1
$$
- 调整过程：
左子堆和右子堆递归调用buildHeap（建堆的函数），对根结点调用percolateDown
=>也就是从编号最大的非叶结点开始percolateDown，逆向向上
```cpp
template <class Type>
void priorityQueue<Type>::buildHeap()
{
    for (int i = currentSize / 2; i > 0; i--)//从下至上调整
        percolateDown(i);
}
```
来个例子：
![](https://notes.sjtu.edu.cn/uploads/upload_40f63b47352ec479688dc8ef4b1f71ef.png =500x)
![](https://notes.sjtu.edu.cn/uploads/upload_c95a4472761881b81da5e1ad8969c9a8.png =500x)
==注意：buildheap一次性建堆和一个空堆逐个插入数据是不一样的两个过程，一个全插入再调整位置，另一个一遍插入一遍调整位置==

### 应用
因为是优先级队列，所以就是有优先级区分的排队系统的背景都可以用了

```
第二部分12.13完成
```
----
# 第三部分 集合结构
第三部分是集合。==说实话感觉线性表和树在编程中似乎用的更多一些。==
## 8.集合与静态查找表
### 8.1集合的基本概念
- 集合中的数据元素除了属于同一集合之外，没有任何逻辑关系。
- 在集合中，每个数据元素有一个区别于其他元素的**唯一标识**，通常称为**键值或关键字值**
#### 集合元素的实现
==当时写程序题的时候没有看到这个东西（因为没听课），导致代码总缺点东西:Anguished:
所以这边一定要把这东西放出来:triumph:，虽然不会考==
```cpp
template <class KEY, class OTHER>
struct SET {
    KEY key;//关键字值
    OTHER other;//元素内容
};
```
#### 集合元素的存储
唯一一个仅适合于**存储和处理集合**的数据结构是==散列表==

### 8.2 查找
- 用于查找的集合称之为查找表
查找表分类：静态查找表、动态查找表、内部查找、外部查找

### 8.3无序表的查找
（最无脑的）只能做线性（O(N)）的顺序查找
==废话:triumph:，数据没顺序还怎么优化==
## 8.4有序表的查找
### 顺序查找
按顺序查找即可，只是找不到的话不用查找到表头
### 二分查找
递归，按照中间值的**偏差，即偏大or偏小**选择左边/右边继续查找
==这个东西其实能玩出很多花样的，懂的uu们都是懂的，但是个人认为应该考不到这么难==
```cpp
template <class KEY, class OTHER>
int binarySearch(SET<KEY, OTHER> data[],int size, const KEY &x)
{
    int low = 1, high = size, mid;
    while (low <= high)
    {                           // 查找区间存在
        mid = (low + high) / 2; // 计算中间位置
        if (x == data[mid].key) // 调整位置
            return mid;
        if (x < data[mid].key)
            high = mid - 1;
        else
            low = mid + 1;
    }
    return 0;
}
```
### 插值查找
适用于数据的分布**比较均匀**的情况，外加访问元素比较**费时**的情况
查找位置的估计：
![](https://notes.sjtu.edu.cn/uploads/upload_3157ffc31805a99388d1a68d77f63582.png =500x)
缺点：计算量大
==我也不知道为什么，按理来说就算一次就行啦？:confused:==
==好吧，因为用的是**浮点数计算**，所以慢==

### 分块查找
处理大量数据查找的一种方法。
它把整个有序表分成若干块，块内的数据元素可以是有序存储，也可以是无序的，但**块之间必须是有序的**。 
查找由两个阶段组成：查找块，找到块后就可以查找索引 

## 9.动态查找表
顾名思义，其既要支持快速查找，又要支持插入删除
### 9.1二叉查找树
#### 9.1.1定义
- 左子树上的所有结点（非空）的关键字值均**小于**p结点的关键字值
- 右子树上的所有结点（非空）的关键字值均**大于**p结点的关键字值

==可以让人联想到二分查找的过程==
#### 9.1.2实现
和二叉树的链表实现差不多。不过任何操作都会从根节点开始
##### 查找、插入操作
- 查找：如果被查节点小于根节点，递归查找左子树，否则递归查找右子树（思路和二分查找类似），直到查找成功
- 插入：先查找，直到找到其父结点
（若查找结点，发现结点按照指定方向递归下去时没有结点，这个结点即为父结点（==听不懂没有关系，我讲的很抽象==））。
如果插入值小于根节点，插入到左子树，否则插入到右子树。插入后，新插入的结点总是叶子结点
```cpp
template <class KEY, class OTHER>
void BinarySearchTree<KEY, OTHER>::insert(const SET<KEY,OTHER> &x)// 插入结点（外部调用函数）
{
    insert(x, root);// 调用内部insert函数
}
template <class KEY, class OTHER>
void BinarySearchTree<KEY, OTHER>::insert(const SET<KEY, OTHER> &x, BinaryNode *&t) // 注意&t这个引用符号，可以使插入结点与父结点建立关联
{
    if (t == NULL)
        t = new BinaryNode(x, NULL, NULL);
    else if (x.key < t->data.key)
        insert(x, t->left);
    else if (t->data.key < x.key)
        insert(x, t->right);
}
```
##### 删除操作
根据被删结点与根结点的大小关系，先查找到结点，然后开删
分成三种情况：
1. 叶结点
直接删除（父结点相应指针为空）
2. 有一个子结点
子结点替代原有的父结点的位置，子结点下面不变
3. 有两个子结点
找出**左子树中最大的结点**或**右子树中最小的结点**来替代被删结点，所以就有两种选择
此时用来替代的结点的位置空出来的，等同于结点被删除，因此继续分成上述3类进行调整（即问题递归）
#### 9.1.3性能分析
正常情况下，如果二叉查找树平衡，那么时间复杂度为O(logN)
（平均下来，查找时间在1.38logN，即O(logN)）
在最坏的请况下，二叉查找树会退化为一个单链表。时间复杂度是O(N)

## 9.2 AVL树（二叉平衡树）
- 二叉平衡树是满足某个平衡条件的二叉查找树，其**保证树的高度是O(logN)**，从而操作都是O(logN)
- 最理想是每个节点的左右子树都有同样的高度，不过条件可以放宽一些，因此有了二叉平衡查找树

### 9.2.1定义与条件
**平衡因子（平衡度）**：结点的平衡度是结点的左子树的高度-右子树的高度
空树的高度定义为-1
要求每个结点的平衡因子都为+1（左边多）、-1（右边多）、0（每个结点的左右子树的高度最多差1）
### 9.2.2代码实现
采用二叉链表（即9.1中的），每个结点必须保存平衡信息（树的高度，从而能计算高度差）
#### 查找元素
与9.1完全一样，也可以采取非递归的算法（就是将指针实时变化代替递归）（略，我觉得不重要）
#### 插入元素
分为两种情况
1. 没破坏平衡性：可以直接插入，然后自下而上修改结点平衡度（若有结点平衡度没变，上面的就都不用修改）
2. 破坏了平衡性：需要调整树的结构（单旋转or双旋转），再修改平衡度
- 插入方法：（注：LL和RR、LR和RL是对称的问题，所以解决方法掌握其一即可）
- 因为原来的高度和旋转后的高度是一样的），所以调整一次即可
```flow
st=>start: 从插入位置向根回溯
op=>operation: 重新计算平衡度
op2=>operation: 调整树的结构（分LL&RR、LR&RL两种）
op5=>operation: 节点处重新平衡
e=>end: 调整完毕

cond=>condition: 节点平衡度是否合法？

st->op->cond
op2->op5
op5->e
cond(yes)->e
cond(no)->op2
```
1. **LL&RR处理方法**
![](https://notes.sjtu.edu.cn/uploads/upload_1a7fc5dcc754839a78bf2bda933a55ae.png =600x)
```cpp
//LL
template <class KEY, class OTHER>
void AvlTree<KEY, OTHER>::LL(AvlNode *&t)
{
    AvlNode *t1 = t->left; // 未来的树根
    t->left = t1->right;   // 即BR的变化
    // 危机节点的左子树变成了左子树的右子树
    t1->right = t; // 左子树B的右子树变成了危机节点A
    t->height = max(height(t->left), height(t->right)) + 1;
    t1->height = max(height(t1->left), height(t)) + 1;
    // 高度更新
    t = t1; // 危机节点的左子树变成了树根
}
```
RR方法是LL方法的对称，略
2. **LR&RL处理方法**
![](https://notes.sjtu.edu.cn/uploads/upload_4a333776c37355d5caa5beae6742fcd4.png =600x)
```cpp
//LR
template <class KEY, class OTHER>
void AvlTree<KEY, OTHER>::LR(AvlNode *&t)
{
    //执行两次变换
    RR(t->left);
    LL(t);
}
```
RL方法与LR方法对称，略
#### 删除元素
- 与插入操作一样，失衡节点存在于被删节点到根节点的**路径**上
- 在删除了一个结点后，必须沿着到根结点的路径向上回溯，随时调整路径上的结点的平衡度。
- 删除操作没有插入操作那么幸运。插入时，最多只需要调整一个结点。而删除时，我们无法保证子树在平衡调整后的高度不变。只有当某个结点的高度**在删除前后保持不变**，才无需继续调整。
- 结点删除同二叉查找树。在删除了叶结点或只有一个孩子的结点后，子树变矮，则可能需要调整
一共5种情况：
![](https://notes.sjtu.edu.cn/uploads/upload_72fb2b637a8b25cb33efd700005032b5.png =500x)
![](https://notes.sjtu.edu.cn/uploads/upload_0fd6ae55865bd443aa2ed066f01557ef.png =500x)
![](https://notes.sjtu.edu.cn/uploads/upload_86bde412e8abd311a9baf779c4ee5907.png =400x)

## 9.3散列表
### 9.3.1哈希法
**哈希法**：也称散列法。它不用比较的办法，而是**直接根据所求结点的关键字值 KEY 找到这个结点**。因此，它的时间复杂性为 O(1)。但**不支持有关有序的操作**
- 潜在问题：由于数据元素的关键字并不一定很小，为了解决这个问题，我们需要用一个将大数字**映射**成一个较小的、更容易管理的数字的函数来达到这个目的。将一个项映射成一个较小的下标的函数称为散列函数（hash function）。此外我们希望，能将字符串解释为一个整数（来扩大哈希法的用途）
### 9.3.2哈希函数
- 定义：每个结点在表中的存储位置是由一个函数H确定。该函数以结点的关键字值为参数，**计算**出该关键字对应的结点的存储位置。该函数称为**哈希函数**
选择标准：计算速度快，散列地址尽可能**均匀**，使得**冲突机会尽可能的少**

==以下的方法我觉得了解即可==
```markmap
# 常用的函数
## 直接地址法
- 直接关键字
- H(key)=a×key+b
（实际中真会取这种函数吗？）
## 除留取余法
- H(key)= key MOD p
或 H(key)= key MOD p + c 
- 多选p为质数（而且比较大）
理由：避免空间浪费
## 数字分析法
- 对关键字集合中的所有关键字，分析每一位上数字分布
取数字分布均匀的位作为地址的组成部分
## 平方取中法
- 如果关键字中各位的分布都比较均匀，但关键字的值域比数组规模大
则可以将关键字平方后，取其结果的中间各位作为散列函数值
由于中间各位和每一位数字都有关系，因此均匀分布的可能性较大。
## 折叠法
- 选取一个长度后，将关键字按此长度分组相加
条件：关键字相当长，以至于和散列表的单元总数相比大得多时，可采用此法
```
### 9.3.3冲突的解决
一般的哈希函数都是多对一。当两个以上的关键字映射到一个存储单元时，称为**冲突或碰撞**
解决方法：==当然是找别的位置咯==
**（闭散列表）：**
**1.线性探测法**
当散列发生冲突时，探测下一个单元，直到发现一个空单元
**查找**：算出来位置之后，找不到的话就位置+1
**删除**：一般来讲，删除某一元素，先要找到该元素，然后把该空间的内容清空。但这样就给查找带来了问题，某些元素会查不到==（ppt上这么说的，我不知道是啥意思）==。解决的方案是采用迟删除，即**不真正删除元素**，而是做一个**删除标记**
**2.二次探测法**
地址序列（冲突后）：![](https://notes.sjtu.edu.cn/uploads/upload_0d00f17ffbf76593ddc792bb46a9c846.png =200x)
这里有个定理：如果采用二次探测法，并且表的大小是一个素数，那么，如果表至少有一半是空的，新的元素总能被插入。而且，在插入过程中，没有一个单元被探测两次。（证明略）
**3.再次散列法**
采用第二个散列函数（**再散列**）。第i次碰撞时，地址为f(i) = hash1(x)+i×hash2(x)
Hash2的选择是非常重要的。建议采用hash2(x) = R - (x mod R)，其中R是小于表长的一个素数
**（开散列表）：**
将碰撞的结点存放在散列表外的各自的线性表中（链接法）
![](https://notes.sjtu.edu.cn/uploads/upload_89f2c2bb4bbf266df2846afc9839ba8a.png =400x)
- 散列表保存在一个数组中，数组的每个元素是一个指针，指向对应的单链表的首地址
单链表不带头结点

## 10.排序
==排序这个东西为什么放在第三部分第十章，这是个值得思考的问题。个人认为应该属于线性表的内容，不过你说排序前元素的整体内部排列就和集合一样，我觉得也没问题。==
==排序本身内容还是很重要的，最好能熟练掌握==
### 10.0部分概念
- **排序**：把集合中的数据元素按照它们的**关键字**的非递减或非递增序排成一个序列
- **稳定与非稳定**排序：多个**关键字值相同**的数据元素经过排序后，这些数据元素的**相对次序保持不变**，则**稳定**，反之则**不稳定**
- **内排序**与**外排序**：
**内排序**是指被排序的数据元素全部存放在计算机的内存之中，并且在内存中调整数据元素的相对位置。
**外排序**是指在排序的过程中，数据元素主要存放在外存储器中，借助于内存储器逐步调整数据元素之间的相对位置。
==（真会考这么细吗?!:confused:）==

来一张各个排序的复杂度和稳定性的表格，大家可以了解一下，不要求背的（网上找的，仅供参考，选择排序应该是稳定的，另外基数排序这里有问题）
![](https://notes.sjtu.edu.cn/uploads/upload_4697cf6bca50fede912f214119d6aa34.png =700x)

### 10.1插入排序
首先将由第一个数据元素组成的序列看成是有序的，然后将剩余的n-1个元素依次**插入**到前面的已排好序的子序列中去，使得每次插入后的子序列也是有序的。
#### 10.1.1直接插入排序
- 顾名思义，直接一个个进行比较，找到正确的地方，插入即可
- 时间复杂度是O(N^2^)
```cpp
for (int j = 1; j < size; ++j)
{
    tmp = a[j];
    for (k = j - 1; tmp.key < a[k].key && k >= 0; --k)
        a[k + 1] = a[k];
    // 当插入的元素小于前面的元素时，将前面的元素后移
    a[k + 1] = tmp; // 将tmp插入到合适的位置
}
```
#### 10.1.2折半插入排序
- 顾名思义，利用二分查找法，快速地找到a[j]的插入位置。从而达到减少比较次数的目的（O(logn)的级别）
- 最坏情况下总的移动次数还是O(n^2^)，这意味着找的效率高了，**移动元素的效率没有高**，故时间复杂度还是O(N^2^)==害，一个悲伤的故事==

#### 10.1.3希尔排序
- 插入排序算法的改进
- 从前面悲伤的故事，我们看到插排效率低主要是因为**大量的移动**
- **希尔排序**先是比较那些离得稍远些的元素进行移动（从而不是一个一个移动交换），然后再不断缩小区间，逼近并变成直接插入排序
- 具体工作原理：
设待排序的对象序列有n个对象，
首先取一个整数gap < n作为增量，
将全部对象分为**n/gap（向上取整）个子序列**，
所有距离为gap的对象**放在同一个序列中**，
在每一个子序列中分别**施行直接插入排序**，
然后**缩小**增量gap，
重复上述的子序列划分和排序工作，直到最后取gap为1为止。
==还是看图舒服==：
![](https://notes.sjtu.edu.cn/uploads/upload_10838e6b10fea5fe0f7fed96ac56bb46.png)
（一步步缩小序列，最终成为直接插入排序）
希尔建议gap从N/2开始平分直到gap为1，之后程序可终止。
应用希尔增量，最坏的时间复杂性是O(N^2^)，平均时间复杂性是O(N^3/2^)
- 程序中的唯一关键点，就是多了个希尔增量step，控制插排的序列长度
```cpp
for (step = size / 2; step > 0; step /= 2) // step为希尔增量
    for (i = step; i < size; ++i)
    {
        tmp = a[i];
        // 每次移动step步的插入排序
        for (j = i - step; j >= 0 && a[j].key > tmp.key; j -= step)
            a[j + step] = a[j];
        a[j + step] = tmp;
    }
```

### 10.2选择排序
从n个元素开始，每次从剩下的元素序列中**选择**关键字最小（也可以是最大）的元素，直至序列中最后只剩下一个元素为止。
这样，把每次得到的元素排成一个序列，就得到了按非递减序排列的排序序列。 
#### 10.2.1直接选择排序
- 时间复杂度O(N^2^)
==请自行与插入排序进行对比，观察两者的区别（一个是拿来的就是最小的，一个是拿来然后找位置）==
![](https://notes.sjtu.edu.cn/uploads/upload_31b900138bc2af51f4ebdc0fc115d719.png =500x)
```cpp
for (i = 0; i < size - 1; ++i)
{
    min = i;
    //找到剩下未排序的元素中的最小值
    for (j = i + 1; j < size; ++j)
        if (a[j].key < a[min].key)
            min = j;
    tmp = a[i];
    a[i] = a[min];
    a[min] = tmp;
}
```
#### 10.2.2堆排序
- 核心：预处理数据，利用O(N)的步骤构建堆，实现O(logN)的查找效率

直接选择排序在n个元素中选出最小元素需要n-1次比较。而利用基于堆的优先级队列选出最小元素只需要O(logN)的时间
- 排序N个元素，步骤如下：
应用buildHeap对N个元素创建一个优先级队列
通过调用N次deQueue取出每个项，结果就排好序了。 
时间效益：建堆用了O(N)的时间，deQueue取出最小的项是对数时间。因此总的时间（N个数）是O(NlogN)。
- 注意与优先级队列中的堆有三个细小的区别：
堆排序用的是最大堆
为了和其他的排序函数保持一致，数据从位置0开始存储。因此，对位置i中的结点，父结点在位置（i – 1）/ 2，左孩子在位置2i + 1，右孩子紧跟着左孩子
在向下过滤时需要告知当前堆的大小（需要额外传参）

### 10.3交换排序
根据序列中两个数据元素的比较结果来确定是否要交换这两个数据元素在序列中的位置。
通过交换，将关键字值较大的数据元素向序列的尾部移动，关键字值较小的数据元素向序列的头部移动。 
#### 10.3.1冒泡排序
==曾经很喜欢用冒泡排序，因为过程容易理解而且稳定，后来发现sort()是真的方便
（sort()是一个已经有的函数，不用自己写，采用快排，效率高，真香！）==

从头到尾比较相邻的两个元素，将小的换到前面，大的换到后面。经过了从头到尾的一趟比较，就把最大的元素交换到了最后一个位置。这个过程称为一趟起泡。
如此类推，经过第n-1趟起泡，将倒数第n-1个大的元素放入第2个单元。从而排序完成。 
- 时间复杂度O(N^2^)
![](https://notes.sjtu.edu.cn/uploads/upload_a75bc811a311fad0c1011f9566b5e2f6.png =500x)
（这个算法（为了出题）能玩出很多的花样，下面的flag就是一个例子，如果一次循环（起泡）没有交换，说明已经有序，那么就无需继续排序，可以直接结束，除此之外的优化技巧更是很多）
```cpp
bool flag = true; // 记录一趟起泡中有没有发生过交换
for (i = 1; i < size && flag; ++i)
{ // size-1次起泡
    flag = false;// 已经发生交换
    for (j = 0; j < size - i; ++j) // 第i次起泡
        if (a[j + 1].key < a[j].key)// 大小逆序，则顺序反了，发生交换
        {
            tmp = a[j];
            a[j] = a[j + 1];
            a[j + 1] = tmp;
            flag = true;
        }
}
```
#### 10.3.2快速排序
在待排序的序列中选择一个数据元素，以该元素为标准，将所有数据元素分为两组，第一组的元素均小于或等于标准元素，第二组的数据元素均**大于标准元素**。第一组的元素放在数组的前面部分，第二组的数据元素放在数组的后面部分，标准元素放在中间。这个位置就是标准元素的最终位置。
这称为一趟**划分**。然后对分成的两组数据**重复**上述过程，直到所有的元素都在适当的位置为止
选择标准元素可能好（选到大小位于中间的元素）、可能坏（就是最大、最小的元素）
具体代码实现：
从右向左开始检查。如果high的值大于k，该位置中的值位置正确，high减1，继续往前检查，直到遇到一个小于k的值。
将小于k的这个值放入low的位置。此时high的位置又空出来了。然后从low位置开始从左向右检查，直到遇到一个大于k的值。
将low位置的值放入high位置，重复第一步，直到low和high重叠。将k放入此位置。
![](https://notes.sjtu.edu.cn/uploads/upload_b144604a717bfbf8725132e3747f9cb5.png =500x)
划分完后，分成两份**继续递归**，直到划分到只有一个
- **平均情况下**复杂度为O(NlogN)（但是最差会到O(N^2^)）
```cpp
template <class KEY, class OTHER>
int divide(SET<KEY, OTHER> a[], int low, int high)
{
    SET<KEY, OTHER> k = a[low];
    do
    {
        while (low < high && a[high].key >= k.key) // 从右向左找第一个大于k的元素
            --high;
        if (low < high) // 将小于k的元素放到左边
        {
            a[low] = a[high];
            ++low;
        }
        while (low < high && a[low].key <= k.key) // 从左向右找第一个小于k的元素
            ++low;
        if (low < high) // 将大于k的元素放到右边
        {
            a[high] = a[low];
            --high;
        }
    } while (low != high);
    a[low] = k; // 将k放到中间
    return low;
}

template <class KEY, class OTHER>
void quickSort(SET<KEY, OTHER> a[], int low, int high)
{
    int mid;
    if (low >= high) // 如果只有一个元素，则直接返回
        return;
    mid = divide(a, low, high);  // 将数组分为左右两部分
    quickSort(a, low, mid - 1);  // 排序左一半
    quickSort(a, mid + 1, high); // 排序右一半
}
```
### 10.4归并排序
#### 10.4.1概念与思路
归并排序的思想来源于合并两个已排序的有序表
- 思想：
如果N=1，已排序
否则，对前一半和后一半分别调用归并排序
归并两个已排序的数组

采用分治法，用**递归**实现
时间复杂度为O(NlogN)，但是需要更多的空间（O(N)）
#### 10.4.2实现
```cpp
int i = left, j = mid, k = 0;
while (i < mid && j <= right) // 两表都未结束
    if (a[i].key < a[j].key)
        tmp[k++] = a[i++];
    else
        tmp[k++] = a[j++];
while (i < mid)
    tmp[k++] = a[i++]; // 前半部分没有结束
while (j <= right)
    tmp[k++] = a[j++]; // 后半部分没有结束

for (i = 0, k = left; k <= right;)
    a[k++] = tmp[i++];

```
```cpp
template <class KEY, class OTHER>
void mergeSort(SET<KEY, OTHER> a[], int left, int right)
{
    int mid = (left + right) / 2;
    if (left == right)
        return;
    mergeSort(a, left, mid);
    mergeSort(a, mid + 1, right);
    merge(a, left, mid + 1, right);
}
```
==实际操作中，其（二路归并排序）第一趟就是相邻两项比较排序==
### 10.5基数排序
称为口袋排序法，时间复杂度O(NlogN)
通过分配的方法对整数进行排序
以排序十进制非负整数为例，可设置10个口袋
首先将元素按个位数分别放入十个口袋，然后将每个口袋中的元素倒出来
按元素的十位数分别放入十个口袋。然后把它们倒出来
再按百位数分配
到最后一次倒出来时，元素就已经排好了序
![](https://notes.sjtu.edu.cn/uploads/upload_c749cee025b96bbdec7eaddd8f80e77c.png)

## 11.外部查找与排序
==内容比较少，但是文字好多呀啊啊啊啊啊==
==大部分内容不用关心如何使用代码实现==
### 11.1主存储器与外存储器
- **主存储器**也被称为内存，是存储正在运行的程序代码及处理数据。
- **外存储器**用于存储长期保存的信息。常用的外存储器有磁盘、磁带、光盘、U盘等，**访问速度慢**，故需考虑减少访问次数。
外存储器中的信息以文件为单位。每个文件在**内存**有一个缓冲区存放正在处理的文件中的数据
外存储器以**数据块**为单位与内存交换信息。当程序需要处理外存储器中的某个数据，则将包含该数据的数据块**读入缓冲区**进行处理
### 11.2外部查找
#### 11.2.1 B树
==理论太多了，精简不了了，尽量理解吧==
想要把磁盘访问次数降低到一个很小的常数，比如说3或者4，我们可以增加树的分叉，就能**降低树的高度**，即采用M叉查找树（M叉查找树的最佳高度为：log~M~N）
**B树**：B树是一棵平衡的M叉查找树，是索引存储中的索引结构
记录可按**添加到文件中的次序**存在数据区中
- 一棵m阶B树或者为空，或者满足以下条件：
根结点要么是叶子，要么**至少有两个儿子**，至多有m个儿子
除根结点和叶子结点之外，每个结点的儿子个数 s 满足 
M/2（向上取整）到M之间
有s个儿子的非叶结点具有n=s-1个关键字，这些结点的数据信息为：
（n, A0, (K1, R1), A1, (K2, R2), A2, ………  (Kn, Rn), An）
![](https://notes.sjtu.edu.cn/uploads/upload_5642bd5e47e04e7786cf7e126e1b58d0.png)

所有的叶子结点都出现在同一层上，即它们的深度相同，并且不带信息
![](https://notes.sjtu.edu.cn/uploads/upload_62d3e88dbff0fb2c9053c35206530a3b.png)
#### 11.2.2 B树的插入
与二叉查找树类似，插入总是在**最底层**。
首先在m阶B树上进行查找操作，确定新插入的关键字key在最底层的非叶结点的插入位置，将 key 和记录的存储地址按序插入到最底层上的某个结点。
- 若被插入结点的关键字个数小于等于m-1，则插入操作结束。
若该结点原有的关键字个数已经等于m，必须分裂成两个结点。

以上面为例，插入50后，关键字个数超了，于是从中间切开，中间的元素放在父节点，而剩下的分裂成2个子结点：
![](https://notes.sjtu.edu.cn/uploads/upload_9bbacdc24550904eaa262b6834b2f3ac.png)

#### 11.2.3 B树的删除
类似于二叉查找树的删除操作，同样采用了“替身”的方法
- 若不是最底层：替身为右子树最左面的关键字或左子树最右面的关键字
- 删除最底层的关键字，则有以下几种情况：
若删除关键字之后，结点的关键字的个数满足B树的结点的定义，删除结束。
若删除后关键字个数**小于下限**：
向结点的左或右兄弟结点**借**一个关键字过来。
若该结点的左或右兄弟结点的关键字的个数正好为下限，则合并结点
#### 11.2.4 B树占用空间的情况（似乎没有特别重要）
将一个磁盘块作为一个B树的结点。假设一个块的容量max字节
如果每个键要占用key个字节。在一棵M阶B树中，可以有M-1个键，总的数据量是
  (M-1)* key + M个分支的地址 + （M-1个关键字对应记录的存储地址）
#### 11.2.5 B+树
B+树是既能提供随机查找，也能提供顺序访问的存储结构。（B树不适合顺序访问）
M阶的B+树是具有以下性质的M叉树：
数据记录被存贮在**叶子**中。
非叶子结点至多保存M-1个键来**引导查找**，键i表示子树i+1中键的**最小值**。
根有2到M个儿子。
除根之外所有的非叶结点的儿子数为M/2（向上取整）到M之间。这保证了B树不会退化成二叉树。
所有的叶子都在同一层上，并且对于某个L要有M/2（向上取整）到L个数据项 
所有的叶子结点连成一个单链表
![](https://notes.sjtu.edu.cn/uploads/upload_4ef3df226ab65b0ef6e87720200dd5ee.png)
#### 11.2.6 B+树的插入
- 叶结点不满：把新节点**插入叶子**，重新调整该叶子中数据的顺序 
- 叶子已经装满 ：通过**分裂**该叶子，形成两个半满的叶子来插入一个新的项，并更新父节点
如果父亲的儿子数量已经满了，我们就继续分裂父亲。最坏情况要**分裂根**（这就是为什么根节点允许只有两个孩子） 
#### 11.2.7 B+树的删除
删除操作首先查找到要删除的项，然后删除它 
如果此时它所在的叶子的元素数量正好满足要求的最小值，删除该项就会使它低于最小值 
如果邻居不是最少的情况，就**借**一个过来领养；
如果邻居也处于最少的情况，就把两个结点**合并**成一个满的结点。
很不幸的是，在这种情况下父亲就失去了一个儿子。如果它引起父亲的儿子数少于了最小值，我们就要使用同样的策略了。这个过程**一直向上**进行过滤到根。如果在寄养的过程中，根只剩下了一个儿子，**就把根删除**，让它的儿子作为新的树根，这也是唯一能使B树变矮的情况。 
```
似乎可以做个思维导图
```
### 11.3外排序
#### 11.3.1总述
由于一次外存操作所需的时间可以执行数百条甚至上千条指令，因此在外排序中主要考虑的是如何减少外存储器的读写 
在外存上进行排序的最常用的方法是利用归并排序，因为归并排序只需要访问被归并序列中的第一个元素，这非常适合于顺序文件。
外排序由两个阶段组成，下面一一介绍
#### 11.3.2预处理阶段
**预处理阶段**：根据内存的大小将一个有n个记录的文件分批读入内存，用各种内排序算法排序，形成一个个有序片段。
如果能够让每个初始的已排序片段包含更多的记录，就能减少排序时间。
**置换选择法**可以在只能容纳p个记录的内存中生成平均长度为2p的初始的已排序片段。 
至于如何置换的，看图就行了，下面的例子中内存只能容纳3个记录。
- 从输入磁带读入下一个元素。
如果它比刚才写出去的元素大，则把它**加入**到优先级队列；
否则，它**不可能进入当前的已排序片段**。因为优先级队列比以前少了一个元素，该元素就被放于优先级队列的**空余位置**（用于下个片段的排序）
根据数据的特点，我们能排一段是一段，一直到文件结束
![](https://notes.sjtu.edu.cn/uploads/upload_88e98b4933edda0d9d6717b34401bd3b.png)
#### 11.3.3归并阶段
**归并阶段**：将这些有序片段逐步归并成一个有序文件。 
归并时，每次将两个有序文件归并成一个有序文件
如果生成的有序片段数是M，则归并次数为log~2~M（向上取整）
以下是一个例子，M=3
![](https://notes.sjtu.edu.cn/uploads/upload_919e430706c605da83b9fa52b4938331.png)
从输入磁带上一次读入M个记录，对它们进行内排序，然后把已排序片段轮流写到B1和B2。回绕所有的磁带。
（注，以下地方原有错误，已经修复）
![](https://notes.sjtu.edu.cn/uploads/upload_24db6650acca8038ee617a70b365a283.png)
取每条磁带上的第一个已排序片段，把它们归并起来，并把结果写到A1。然后，从每条磁带上取下一个已排序片段，把它们归并起来，结果写到A2。继续这个过程，轮流把结果写到A1和A2， 
![](https://notes.sjtu.edu.cn/uploads/upload_2a5d152b628af2aeb954eb4502f872de.png)
回绕四条磁带，重复同样的步骤，这次使用A磁带作为输入，而B磁带作为输出。
重复步骤二和三，直到剩下一个长度为N的已排序片断
![](https://notes.sjtu.edu.cn/uploads/upload_91c16b5984648ce1cc5e43884f0f89bb.png)
##### 多路归并
同时将k个有序文件归并成一个
**优点**：减少归并次数，只需要log~k~m次归并
**缺点**：归并时找最小元素的操作复杂，通常可以将每个文件的第一个记录组成一个优先级队列。
K路归并需要2k条磁带。A~1~到A~k~和B~1~到B~k~。归并数据在A上
过程：==就是把2条变成k条而已==
回绕2k根磁带
归并A~1~到A~k~条磁带上的有序片段轮流放入B1到Bk
回绕所有磁带
归并B~1~到B~k~条磁带上的有序片段轮流放入A1到Ak
重复上述过程，直到只剩下一个有序片段
##### 多阶段归并 
磁带上的K路归并策略需要用2K条磁带，这可能限制了它在某些应用中的使用。
可以仅用K+1根磁带实现K路归并，这称为多阶段归并
==也就是比如3个磁带，我拿一个片段+另一个片段的一部分归并，然后轮流归并==
下图：T2的13段与T3的13段归并存到T1，T1中8段和T2中8段归并存到T3，以此类推
![](https://notes.sjtu.edu.cn/uploads/upload_1915d52fc9849a9b94100b57233ec608.png)
- 如何分配：
如果已排序片段的数目是一个斐波纳契数FN，那么分布最好的方法把它们分解成两个斐波纳契数FN-1和FN-2。
否则，为了将已排序片段数增加到一个斐波纳契数，必须在磁带上填充虚拟的已排序片段。 


==第12章应该没学==

# 第四部分 图状结构
==最后一个部分啦==
## 13.图
### 13.1图的定义
图可以用G=(V,E)表示。其中，V是顶点的集合，E是连接顶点的边（弧）的集合。

如果边是有方向的，称为**有向图**。有向图的边用<>表示。<A,B>表示从A出发到B的一条边。在有向图中，<A,B>和<B,A>是不一样的。
V = {A,B,C,D},
E = {<A,B>,<B,A>,<A,C>,<C,A>,<C,D>,<D,A>}表示的图如下所示
![](https://notes.sjtu.edu.cn/uploads/upload_e9ce62c3fc49b878f369deb7ebd93cc3.png =200x)

如果边是无方向的，称为**无向图**。无向图的边通常用圆括号表示。（A，B）表示顶点A和B之间有一条边。无向图也称为双向图。
V = {A,B,C,D,E}
E = {(A,B),(A,C),(B,D),(B,E),(D,E),(C,E)}
![](https://notes.sjtu.edu.cn/uploads/upload_5de37fc7898a8070890740a23c172f00.png =200x)

**加权图**：边被赋予一个权值的图称为加权图。如果图是有向的，称为加权有向图，如果是无向的，称为加权无向图。
![](https://notes.sjtu.edu.cn/uploads/upload_2ae57ec6091043fff5c9176abf3e0c6f.png =500x)

### 13.2图的术语
==概念有点多啊==
```markmap
# 图的术语
## 区分有向图无向图
### 有向图
#### 邻接
- <Vi,Vj>是图中的一条边，则称**Vi邻接到Vj**，或Vj和Vi邻接
#### 入度
- 有向图中进入某一结点的边数，称为该结点的入度
#### 出度
- 有向图中离开某一结点的边数，称为该结点的出度
#### 连通性
- 强连通图：有向图 G 的任意两点之间都是连通的，则称 G 是强连通图。
- 强连通分量：极大连通子图
- 弱连通图：如有向图G不是强连通的，但如果把它看成是无向图时是连通的，则称该图是弱连通的
- 有向无环图：图中没有环，简写为DAG
#### 有向完全图
- 有向完全图：每两个节点之间都有两条弧的有向图称为有向完全图。有向完全图有n(n-1)（排列组合2C2n）条边。其中n是结点个数

### 无向图
#### 邻接
- (Vi,Vj)是图中的一条边，则称Vi和Vj是邻接的
#### 度
- 无向图中邻接于某一结点的边的总数
#### 连通性
- 连通：顶点v至v’ 之间有路径存在
- 连通图：无向图 G 的任意两点之间都是连通的，则称 G 是连通图。
- 连通分量：非连通图中的极大连通子图
#### 完全图
- 每两个节点之间都有边的无向图称为**完全图**。
完全图有n(n-1)/2（排列组合C2n）条边。其中n是结点个数


## 不区分
### 子图
- 边&顶点均为另一个图的子集
- 顾名思义
### 路径
- 对1<i<N，结点序列w1,w2,……wN 中的结点对（wi, wi+1）
都有（wi, wi+1）∈ E或<wi, wi+1> ∈ E
那么，w1,w2,……wN是图中的一条路径。
#### 非加权的路径长度
- 组成路径的边数，对于路径w1,w2,……wN，非加权路径长度为N-1
#### 加权路径长度
- 路径上所有边的权值之和。
#### 简单路径
- 一条路径上的所有结点，除了起始结点和终止结点可能相同外，其余的结点都不相同
#### 回路（环）
- 是一条简单路径，其起始结点和终止结点相同，且路径长度至少为1
```
还有个**生成树**
连通图的极小连通子图。包含图的所有 n 个结点，但只含图的n-1条边。在生成树中添加一条边之后，**必定会形成回路或环**。
==是不是有点眼熟，因为在电路理论里面见过，就是电路图中的树，加一个连支形成回路==

### 13.3图的存储
#### 13.3.1（加权）邻接矩阵
- 有向图：
设有向图具有n个结点，则用n行n列的布尔矩阵A表示该有向图
如果i至j有一条有向边, A[i,j]=1 ,如果 i 至 j 没有一条有向边,A[i,j]=0
实际实现：分别用 0、1、2、3 分别标识结点A、B、C、D。而将真正的数据字段之值放入一个一维数组之中
![](https://notes.sjtu.edu.cn/uploads/upload_1cd9b0817e81b2c901849beb9640919a.png =500x)
- 无向图：
具有n 个结点，则用n行n列的布尔矩阵A表示该无向图
i至j有一条无向边：A[i,j]=1；i至j没有一条无向边：A[i,j]=0
实际实现和有向图类似
![](https://notes.sjtu.edu.cn/uploads/upload_4ef40e545d54442153ba8357f10d2b94.png =500x)
- 加权有向图（无向图同理）：
设有向图具有n个结点，则用n行n列的矩阵A表示该有向图； 如果i至j有一条有向边且它的权值为a ，则A[i,j]=a 。如果i至j没有一条有向边。则A[i,j]=空或其它标志
![](https://notes.sjtu.edu.cn/uploads/upload_bbc23e437133b65dd4638436d8afd3ae.png =500x)

- 邻接矩阵的特点：
优点：寻找边仅需O(1)
缺点：空间复杂度O(n^2)，在边数少的时候十分致命
#### 13.3.2邻接表
设有向图或无向图具有 n 个结点，则用结点表、边表表示该有向图或无向图。
结点表：用数组或单链表的形式存放所有的结点值。如果结点数n已知，则采用数组形式，否则应采用单链表的形式。
边表（边结点表）：每条边用一个结点进行表示。同一个结点出发的所有的边形成它的边结点单链表。
![](https://notes.sjtu.edu.cn/uploads/upload_0fc8c5e0b46a7b7122f383afbff6d7d9.png =500x)

邻接表是图的标准存储方式
- 优点：
- 内存 ＝  结点数 ＋ 边数，处理时间也是结点数 ＋ 边数，即为O(|V|+|E|)。
当谈及图的线性算法时，一般指的是O(|V|+|E|)
- 缺点：
确定 i --> j 是否有边，最坏需耗费 O(n) 时间。
无向图同一条边表示两次。边表空间浪费一倍。
有向图中寻找进入某结点的边，非常困难。
### 13.4图的遍历
#### 13.4.1深度优先搜索
==就是一条路走到黑，然后如果没遍历完，那就回去找别的路继续走到黑……，直到遍历结束==
1、选中第一个被访问的顶点；
2、对顶点作已访问过的标志；
3、依次从顶点的未被访问过的第一个、第二个、第三个…… 邻接顶点出发，进行深度优先搜索；
4、如果还有顶点未被访问，则选中一个起始顶点，转向2；
5、所有的顶点都被访问到，则结束。
这样遍历会获得一棵深度优先生成树
在进行深度优先搜索 DFS 时，有时并不一定能够保证从某一个结点出发能访问到所有的顶点
在这种情况下，必须再选中一个未访问过的顶点，继续进行深度优先搜索。直至所有的顶点都被访问到为止。这时会生成深度优先生成**森林**

示例：
![](https://notes.sjtu.edu.cn/uploads/upload_6fdf5a349ee004334667d2564be9a8af.png =500x)
```cpp
for (int i = 0; i < Vers; ++i)
    visited[i] = false;

cout << "当前图的深度优先遍历序列为：" << endl;
for (i = 0; i < Vers; ++i)
{
    if (visited[i] == true)
        continue;
    dfs(i, visited);
    cout << endl;
}

void dfs(v,visited)
{
    visited[v] = true;
    for 每个 v的邻接点w 
        if (!visited[w])
            dfs(w, visited);//递归调用
}
```

**广度优先搜索**类似于树的从树根出发的按照层次的遍历。
==是一个点，先把这个点能走的路都走一遍，而且就走一下，然后再继续到下一点遍历==
1、选中第一个被访问的顶点；
2、对顶点作已访问过的标志；
3、依次访问已访问顶点的未被访问过的第一个、第二个、第三个……第 m 个邻接顶点 W1 、W2、W3…… Wm ，进行访问且进行标记，转向3；
4、如果还有顶点未被访问，则选中一个起始顶点，转向2；
5、所有的顶点都被访问到，则结束。 
示例：
例如，从5开始广度优先搜索这个图，得到的遍历序列为：5，6，7，2，4，3，1。 ![]
![](https://notes.sjtu.edu.cn/uploads/upload_851442e4c2240680939215a983b8bc51.png =500x)
```cpp
bool *visited = new bool[Vers];
int currentNode;
linkQueue<int> q;
edgeNode *p;
for (int i = 0; i < Vers; ++i)
    visited[i] = false;
cout << "当前图的广度优先遍历序列为："<< endl;

for (i = 0; i < Vers; ++i)
{
    if (visited[i] == true)
        continue;
    q.enQueue(i);
    while (!q.isEmpty())
    {
        currentNode = q.deQueue();
        if (visited[currentNode] == true)//访问过则跳过
            continue;
        cout << verList[currentNode].ver << '\t';
        visited[currentNode] = true;
        p = verList[currentNode].head;
        while (p != NULL)
        {
            if (visited[p->end] == false)//未访问过则入队
                q.enQueue(p->end);
            p = p->next;
        }
    }
    cout << endl;
}
```

==两个的区别：一个的调用结构是**栈**，另一个是**队列**==
时间复杂度：两个函数将对所有的顶点和边进行访问，因此它的时间代价和顶点数 |V| 及边数 |E| 是相关的，即是O(|V|+|E|)。
如果图是用邻接矩阵来表示，则所需要的时间是O（|V|^2^）

## 13.5图遍历的应用
### 13.5.1无向图的连通性
深度优先搜索和广度优先搜索都可以用来测试无向图的连通性。
如果无向图是连通的，则从无向图中的任意结点出发进行深度优先搜索或广度优先搜索都可以访问到每一个结点。
### 13.5.2欧拉回路
如果能够在一个图中找到一条路径，使得该路径对图的每一条边正好经过一次，这条路径被称为欧拉路径。
如果再增加一个附加条件，即起点和终点是相同的，这条路径被称为欧拉回路。欧拉回路问题也被称为一笔画问题。
#### 欧拉回路的性质
如果有奇数桥的地方不止两个，满足要求的路径是找不到的。
如果只有两个地方有奇数桥，可以从这两个地方之一出发，经过所有的桥一次，再回到另一个地方。
如果都是偶数桥，从任意地方出发都能回到原点。
#### 使用dfs进行遍历
执行一次深度优先的搜索。从起始结点开始，沿着这条路一直往下走，直到无路可走。而且在此过程中不允许回溯。如果遍历完了发现边没有走完，则找出路径上的另外一个尚有未访问的边的顶点，开始另一次深度优先的搜索，将得到的遍历序列拼接到原来的序列中，直到所有的边都已被访问。
![](https://notes.sjtu.edu.cn/uploads/upload_3caf03c26dff8bc669550959bf4a71a1.png =500x)
#### 代码实现（自己看别的ppt吧，代码有点多了）

### 13.5.3有向图的连通性
对有向图，深度优先搜索可以测试是否强连通，并找出所有强连通分量
找强连通分量的方法
从任意节点开始深度优先遍历G，得到深度优先森林。对每一棵树按照生成顺序依次进行后续遍历，按照遍历顺序记录每个节点编号
将G的每条边逆向，形成Gr。从编号最大的节点开始深度优先遍历Gr。得到的深度优先遍历森林的每棵树就是G的强连通分量。
![](https://notes.sjtu.edu.cn/uploads/upload_daab4bac5320d8188217cd9f6abd6adf.png =500x)
![](https://notes.sjtu.edu.cn/uploads/upload_ed8e25b3fc90a95f86728d8dcf88ede6.png =500x)


### 13.5.4拓扑排序
结果不一定唯一，所以代码实现应该只能输出其中的一种情况
过程：序列中第一个元素必须无前驱（入度为0）
后驱：必须等到其前驱输出后才能输出
如果图以邻接表表示：O（V+E）（V为寻找入度为0节点，E为搜索后续节点）
![](https://notes.sjtu.edu.cn/uploads/upload_113617dabfc3e5ee970c7c07bbb34065.png =500x)
可行的排课：
方案1：
  1，2，3，4，5，6，7
方案2：
  1，2，3，5，6，4，7
方案3：
  1，2，3，5，6，7，4
……

#### 实现
计算每个结点的入度，保存在数组inDegree中；
检查inDegree中的每个元素，将入度为0的结点入队；
不断从队列中将入度为0的结点出队，输出此结点，并将该结点的**后继结点**的入度减1；如果某个邻接点的入度为0，则将其入队。
下图：从左到右依次为各课程入度随程序运行的变化
![](https://notes.sjtu.edu.cn/uploads/upload_0893f7efa7571e3687ccc3016b12e500.png =500x)
```cpp
template <class TypeOfVer, class TypeOfEdge>
void adjListGraph<TypeOfVer, TypeOfEdge>::topSort() const
{
    linkQueue<int> q;
    edgeNode *p;
    int current, *inDegree = new int[Vers];
    for (int i = 0; i < Vers; ++i)
        inDegree[i] = 0;
    for (i = 0; i < Vers; ++i)
        for (p = verList[i].head; p != NULL; p = p->next)
            ++inDegree[p->end];//计算入度
    for (i = 0; i < Vers; ++i)
        if (inDegree[i] == 0)
            q.enQueue(i);//入队入度为0的顶点
    cout << "拓扑排序为：" << endl;
    while (!q.isEmpty())
    {
        current = q.deQueue();
        cout << verList[current].ver << '\t';
        for (p = verList[current].head; p != NULL; p = p->next)
            if (--inDegree[p->end] == 0)//减去入度，如果入度为0，则入队
                q.enQueue(p->end);
    }
    cout << endl;
}
```
### 13.5.5关键路径
**AOE网络**：顶点表示事件，有向边权值代表时间，指向本身代表顺序（有向图）
完成整项工程至少需要多少时间，从源点到收点最长路径的长度，称为关键路径
==也就是说，关键路径是最长的（即花费最多的）路径，而非最短的
在实际生活中，可以把节点认定为生产的一道道工序==
![](https://notes.sjtu.edu.cn/uploads/upload_12fb2e16c90b1dbf5bbbcedef7c7c2f2.png =500x)
几个概念：
最早发生时间：（前驱节点最早时间+边）的最大值，否则会浪费时间，从而影响整体
以上面为例子：
![](https://notes.sjtu.edu.cn/uploads/upload_66b0f7d47c4ceb03ed4d2eafec07172c.png =600x)
最晚发生时间：（后继节点最晚时间-边）的最小值，否则会耽搁进程，影响整体完成时间（即关键路径）
![](https://notes.sjtu.edu.cn/uploads/upload_ca07275fda4e040abee024bf952232a9.png =600x)

最早最晚时间相等，就是关键路径上的顶点（==意思就是说，关键路径上的节点没有可以选择发生的时间区间，一旦需要发生就会直接发生（听不懂也没关系）==）
实现：在拓扑排序后，依据排序结果遍历节点，寻找min的值

==后面的应该都没学==
==完结撒花:tada:==

----